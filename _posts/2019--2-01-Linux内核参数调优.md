---
layout: post
title:  "一次问题排查引发的Linux内核TCP/IP协议栈参数调优"
date:   2019-02-02 9:14:10
categories: jekyll
comments: true
tags:
    - Linux内存内核
    - TCP/IP
---

* content
{:toc}

# 前言

**背景**

在Linux平台部署并测试服务器的性能时，在刚开始把

```java
 
 int socket_bind_listen
  
  // 虽然设置为2048 实质上最大只能为128个
 
    if(listen(listen_fd, 2048) == -1)
        return -1;
 ```


函数的第二个参数backlog 设置为50，客户端的请求有很多都不能被服务器不能正常处理，大概成功处理请求和处理失败的请求各种一半。

出现上述问题，我首先是查看了下服务器下套接字请求的状态,主要是下面两个命令和wireshark抓包工具。

**意图**

因此在该问题过后，打算写一篇Linux下网络性能排查和linux TCP/IP内核协议stack相关的参数优化blog,算是做个总结吧

```
ss 
netsat
```

这个图片是我阿里云服务器上面的演示图片，其中state 状态代表socket所处的状态，UNCONN其实就是代表close状态

[![A2ha3d.md.png](https://s2.ax1x.com/2019/04/04/A2ha3d.md.png)](https://imgchr.com/i/A2ha3d)

[![A24ys1.md.png](https://s2.ax1x.com/2019/04/04/A24ys1.md.png)](https://imgchr.com/i/A24ys1)


**发现服务器发送大量的RST重置标识符，利用wireshark工具进行捉取
设置如下过滤条件**


>tcp[13]&4==4 || tcp[13]&4==14 #tcp的flag在偏移13字节的地方，占据1


[![A27fv4.md.png](https://s2.ax1x.com/2019/04/04/A27fv4.md.png)](https://imgchr.com/i/A27fv4)


## 问题排查


上网查了下，是长连接队列参数backlog设置过小,而服务器端accept()的处理速度跟不上队列填满的速度，导致队列始终是满的，然后就不理会客户的其他连接请求，只能抛去的原则导致了客户connect超时，并且处理效率低下。服务器发送了大量的设置RST报文给客户端

利用

主要涉及到的unix网络编程函数
1. accept()
2. listen() 服务器端调用
3. close() 一般是客户端主动端断开连接


## 三次握手过程

回顾下三次握手的具体过程，以及套接字所处的状态。


[![A2hmh4.md.png](https://s2.ax1x.com/2019/04/04/A2hmh4.md.png)](https://imgchr.com/i/A2hmh4)

**socket的11种状态，假设我们假定A服务请求连接B服务。**

1. LISTEN：开始建立连接，此时socket已经初始化成功，正在等待连接
2. SYN-SENT：A成功发送连接请求给B，等待对方响应
3. SYN-RECEIVED：B接收到A的连接请求，并回复了确认进行连接给A，此状态表示正在等待A也回复确认收到此消息
4. ESTABLISHED：表示连接已经成功建立；这个状态是连接阶段中进行数据传输的正常状态


## 握手参数调优
从三次握手过程当种，先谈论两个两个参数，
1.  syn queue 半连接队列
2.  accept queue 全连接队列

在内核对相应的参数设置如下
1. /proc/sys/net/ipv4/tcp\_max\_syn\_backlog 半连接队列 Linux下默认值是1024，加大队列长度为8192，可以容纳更多等待连接的网络连接数。
2. cat /proc/sys/net/core/somaxconn 全连接队列 最大可以设置为128


**上面的两个是我自己项目服务器当中要设置的参数**


然后除了上面两个，我顺便复习了下其他的相关参数设置

- tcp\_synack\_retries 服务器在没有收到客户端第三次ack的报文，重发ack+syn报文的重试次数，默认情况下设置为5，总共消耗的时间为65s, 

- tcp\_abort\_on\_overflow 全连接队列满了之后，服务器发送rst 给客户端的ack 第二次确认报文


## syn flood攻击

**问题**

当我们将全连队设置为最大值，但是在某种特殊的情况下，比如碰到DDos恶意攻击，当 SYN queue 满了，系统还在不断的收到 SYN 包时，系统怎么处理的？

**解决方案**

- net.ipv4.tcp_syncookies 

**工作原理**

- tcp_syncookies 是用来防止 SYN flood 攻击，其原理是在半连接队列满时，SYN cookies 并不丢弃 SYN 请求，而是将源目的 IP、源目的端口号、接收到的 client 端初始序列号以及其他一些安全数值等信息进行 hash 运算，并加密后得到 server 端的初始序列号，称之为 cookie。server 端在发送初始序列号为 cookie 的 SYN+ACK 包后，会将分配的连接请求块释放。如果接收到 client 端的 ACK 包，server 端将 client 端的 ACK 序列号减 1 得到的值，与上述要素 hash 运算得到的值比较，如果相等，直接完成三次握手，构建新的连接。SYN cookies 机制的核心就是避免攻击造成的大量构造无用的连接请求块，导致内存耗尽，而无法处理正常的连接请求。



- 当 syn queue 满了，在 Server 端没有开启 syncookies 的时候，即 syncookies=0，server 端会丢弃新来的 SYN 包，而 client 端在多次重发 SYN 包得不到响应而返回 connection time out 错误。但是，当 Server 端开启了 syncookies, 即 syncookies=1，那么 SYN queue 就在逻辑上的没有最大值了，而是忽略内核参数 net.ipv4.tcp_max_syn_backlog 设置的值。Client 端在多次重发 SYN 包得不到响应而返回 connection time out 错误。




## 四次挥手
![A24k2d.png](https://s2.ax1x.com/2019/04/04/A24k2d.png)



**套接字状态**

5. FIN-WAIT-1：等待主动断开连接请求的确认，或者并发请求被拒绝的断开连接，这种状态通常持续时间很短，比较难捕捉，
6. CLOSE-WAIT：B已经收到了A的断开连接请求，正在等待本地应用程序发送断开连接请求
7. FIN-WAIT-2：等待B断开连接操作，这个状态通常持续时间也很短，但是如果B发生阻塞或者其他原因没有关闭连接，那么这个状态就会持续较长时间
8. LAST-ACK：B等待断开连接的确认信号
9. TIME-WAIT：等待一段时间，确认B接收到A的关闭连接确认信号， 2MSL ,主动发起关闭连接的一端 
10. CLOSED：连接完全关闭


## 挥手参数调优

两种异常，以及带来的问题总结

1. 主动关闭方，比如客户端保持了大量的TIME_WAIT状态， 
2. 被动关闭方法， 比如服务器保持了大量的CLOSE_WAIT状态，

## 四次挥手会如果不能顺利完成会影响什么资源

**资源受限**

>因为tcp实质上利用socket 进行通信的，而socket在Linux系统当中是采取一个文件描述符来描述，因此影响的是最终的系统资源，比如导致打开的open files 过多等等情况的



>我们也都知道Linux系统中分给每个用户的文件句柄数是有限的，而TIME_WAIT和CLOSE_WAIT这两种状态如果一直被保持，那么意味着对应数目的通道(此处应理解为socket，一般一个socket会占用服务器端一个端口，服务器端的端口最大数是65535)一直被占用，一旦达到了上限，则新的请求就无法被处理，接着就是大量Too Many Open Files异常，然后tomcat、nginx、apache崩溃。。

### **解决time_wait**

解决这个问题主要是从服务器参数Linux设置思考

2. 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭  
net.ipv4.tcp_tw_reuse = 1  
3. 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭  
net.ipv4.tcp_tw_recycle = 1


### **解决close_wait**

解决该问题主要从应用代码层考虑， 因为导致被动方停在close_wait而没有进入last_ack的是由于服务器端没有正确调用函数close()。


所以如果将大量CLOSE_WAIT的解决办法总结为一句话那就是：查代码。因为问题出在服务器程序里头啊。

1. 关闭socket不及时：例如I/O线程被意外阻塞，或者I/O线程执行的用户自定义Task比例过高，导致I/O操作处理不及时，链路不能被及时释放。
2. 程序Bug，没有正常发送FIN调用close()，这可能是Netty的Bug，也可能是业务层Bug


# tcp 参数列表

在tcp设计当中我们可以对下面的参数进设计

- 开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭；
net.ipv4.tcp_syncookies = 1

- 开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；
net.ipv4.tcp_tw_reuse = 1

- 开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭；
net.ipv4.tcp_tw_recycle = 1

- 系统默认的TIMEOUT时间。
net.ipv4.tcp_fin_timeout = 5

- 当keepalive起用的时候，TCP发送keepalive消息的频度。缺省是2小时，改为20分钟(20*60s)
net.ipv4.tcp_keepalive_time = 1200

- 表示用于向外连接的端口范围。缺省情况下很小：32768到61000，改为10000到65000
net.ipv4.ip_local_port_range = 10000 65000

- SYN队列的长度，默认为1024，加大队列长度为8192，可以容纳更多等待连接的网络连接数
net.ipv4.tcp_max_syn_backlog = 8192


- 系统同时保持TIME_WAIT的最大数量，如果超过这个数字，TIME_WAIT将立刻被清除并打印警告信息。默认为180000，改为5000
net.ipv4.tcp_max_tw_buckets = 5000

1. net.ipv4.tcp_keepalive= 7200 保持长连接状况下的信息等情况

tcp_abort_on_overflow 连接队列满了怎么办在该种情况下面，


tcp_keepalive_intvl/:75
默认值为75
探测消息发送的频率，乘以tcp_keepalive_probes就得到对于从开始探测以来没有响应的连接杀除的时间。默认值为75秒，
也就是没有活动的连接将在**大约11分钟**以后将被丢弃。(对于普通应用来说,这个值有一些偏大,可以根据需要改小.特别是web类服务器需要改小该值,
**15是个比较合适的值。**

# 参考资料

- [Too many open files (CLOSE_WAIT connections) · Issue #4575 · kennethreitz/requests](https://github.com/kennethreitz/requests/issues/4575)

- [关于TCP 半连接队列和全连接队列  |阿里中间件团队博客](http://jm.taobao.org/2017/05/25/525-1/)

- [记一次惊心的网站TCP队列问题排查经历 - 知乎](https://zhuanlan.zhihu.com/p/36731397)

- [(9条消息)Wireshark抓取TCP报文类型为RST的方法 - u010192132的专栏 - CSDN博客](https://blog.csdn.net/u010192132/article/details/44095733)

- [大并发下listen的连接完成对列backlog太小导致客户超时，服务器效率低下 ](https://blog.csdn.net/lizhi200404520/article/details/6981272)

- [How TCP backlog works in Linux](http://veithen.io/2014/01/01/how-tcp-backlog-works-in-linux.html)

- [Linux使用ss命令查看socket状态](https://blog.51cto.com/215687833/1836119)

