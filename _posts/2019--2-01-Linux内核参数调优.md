---
layout: post
title:  "一次问题排查引发的Linux内核TCP/IP协议栈参数调优"
date:   2019-02-02 9:14:10
categories: Linux
comments: true
tags:
    - Linux
    - 网络协议
---

* content
{:toc}

# 前言

**背景**

在Linux平台部署并测试服务器的性能时，在刚开始把

```java
 
 int socket_bind_listen
  
  // 虽然设置为2048 实质上最大只能为128个
 
    if(listen(listen_fd, 2048) == -1)
        return -1;
 ```


函数的第二个参数backlog 设置为50，客户端的请求有很多都不能被服务器不能正常处理，大概成功处理请求和处理失败的请求各种一半。

出现上述问题，我首先是查看了下服务器下套接字请求的状态,主要是下面两个命令和wireshark抓包工具。

**意图**

因此在该问题过后，打算写一篇Linux下网络性能排查和linux TCP/IP内核协议stack相关的参数优化blog,算是做个总结吧

```
ss 
netsat
```

这个图片是我阿里云服务器上面的演示图片，其中state 状态代表socket所处的状态，UNCONN其实就是代表close状态

[![A2ha3d.md.png](https://s2.ax1x.com/2019/04/04/A2ha3d.md.png)](https://imgchr.com/i/A2ha3d)

[![A24ys1.md.png](https://s2.ax1x.com/2019/04/04/A24ys1.md.png)](https://imgchr.com/i/A24ys1)


**发现服务器发送大量的RST重置标识符，利用wireshark工具进行捉取
设置如下过滤条件**


>tcp[13]&4==4 || tcp[13]&4==14 #tcp的flag在偏移13字节的地方，占据1


[![A27fv4.md.png](https://s2.ax1x.com/2019/04/04/A27fv4.md.png)](https://imgchr.com/i/A27fv4)


## 问题排查


上网查了下，是长连接队列参数backlog设置过小,而服务器端accept()的处理速度跟不上队列填满的速度，导致队列始终是满的，然后就不理会客户的其他连接请求，只能抛去的原则导致了客户connect超时，并且处理效率低下。服务器发送了大量的设置RST报文给客户端

利用

主要涉及到的unix网络编程函数
1. accept()
2. listen() 服务器端调用
3. close() 一般是客户端主动端断开连接


## 三次握手过程

回顾下三次握手的具体过程，以及套接字所处的状态。


[![A2hmh4.md.png](https://s2.ax1x.com/2019/04/04/A2hmh4.md.png)](https://imgchr.com/i/A2hmh4)

**socket的11种状态，假设我们假定A服务请求连接B服务。**

1. LISTEN：开始建立连接，此时socket已经初始化成功，正在等待连接
2. SYN-SENT：A成功发送连接请求给B，等待对方响应
3. SYN-RECEIVED：B接收到A的连接请求，并回复了确认进行连接给A，此状态表示正在等待A也回复确认收到此消息
4. ESTABLISHED：表示连接已经成功建立；这个状态是连接阶段中进行数据传输的正常状态


## 握手参数调优
从三次握手过程当种，先谈论两个两个参数，
1.  syn queue 半连接队列
2.  accept queue 全连接队列

在内核对相应的参数设置如下
1. /proc/sys/net/ipv4/tcp\_max\_syn\_backlog 半连接队列 Linux下默认值是1024，加大队列长度为8192，可以容纳更多等待连接的网络连接数。
2. cat /proc/sys/net/core/somaxconn 全连接队列 最大可以设置为128


**上面的两个是我自己项目服务器当中要设置的参数**


然后除了上面两个，我顺便复习了下其他的相关参数设置

- tcp\_synack\_retries 服务器在没有收到客户端第三次ack的报文，重发ack+syn报文的重试次数，默认情况下设置为5，总共消耗的时间为65s, 

- tcp\_abort\_on\_overflow 全连接队列满了之后，服务器发送rst 给客户端的ack 第二次确认报文


## syn flood攻击

**问题**

当我们将全连队设置为最大值，但是在某种特殊的情况下，比如碰到DDos恶意攻击，当 SYN queue 满了，系统还在不断的收到 SYN 包时，系统怎么处理的？

**解决方案**

- net.ipv4.tcp_syncookies 

**工作原理**

- tcp_syncookies 是用来防止 SYN flood 攻击，其原理是在半连接队列满时，SYN cookies 并不丢弃 SYN 请求，而是将源目的 IP、源目的端口号、接收到的 client 端初始序列号以及其他一些安全数值等信息进行 hash 运算，并加密后得到 server 端的初始序列号，称之为 cookie。server 端在发送初始序列号为 cookie 的 SYN+ACK 包后，会将分配的连接请求块释放。如果接收到 client 端的 ACK 包，server 端将 client 端的 ACK 序列号减 1 得到的值，与上述要素 hash 运算得到的值比较，如果相等，直接完成三次握手，构建新的连接。SYN cookies 机制的核心就是避免攻击造成的大量构造无用的连接请求块，导致内存耗尽，而无法处理正常的连接请求。



- 当 syn queue 满了，在 Server 端没有开启 syncookies 的时候，即 syncookies=0，server 端会丢弃新来的 SYN 包，而 client 端在多次重发 SYN 包得不到响应而返回 connection time out 错误。但是，当 Server 端开启了 syncookies, 即 syncookies=1，那么 SYN queue 就在逻辑上的没有最大值了，而是忽略内核参数 net.ipv4.tcp_max_syn_backlog 设置的值。Client 端在多次重发 SYN 包得不到响应而返回 connection time out 错误。




## 四次挥手
![A24k2d.png](https://s2.ax1x.com/2019/04/04/A24k2d.png)



**套接字状态**

5. FIN-WAIT-1：等待主动断开连接请求的确认，或者并发请求被拒绝的断开连接，这种状态通常持续时间很短，比较难捕捉，
6. CLOSE-WAIT：B已经收到了A的断开连接请求，正在等待本地应用程序发送断开连接请求
7. FIN-WAIT-2：等待B断开连接操作，这个状态通常持续时间也很短，但是如果B发生阻塞或者其他原因没有关闭连接，那么这个状态就会持续较长时间
8. LAST-ACK：B等待断开连接的确认信号
9. TIME-WAIT：等待一段时间，确认B接收到A的关闭连接确认信号， 2MSL ,主动发起关闭连接的一端 
10. CLOSED：连接完全关闭


## 挥手参数调优

两种异常，以及带来的问题总结

1. 主动关闭方，比如客户端保持了大量的TIME_WAIT状态， 
2. 被动关闭方法， 比如服务器保持了大量的CLOSE_WAIT状态，

## 四次挥手会如果不能顺利完成会影响什么资源

**资源受限**

>因为tcp实质上利用socket 进行通信的，而socket在Linux系统当中是采取一个文件描述符来描述，因此影响的是最终的系统资源，比如导致打开的open files 过多等等情况的



>我们也都知道Linux系统中分给每个用户的文件句柄数是有限的，而TIME_WAIT和CLOSE_WAIT这两种状态如果一直被保持，那么意味着对应数目的通道(此处应理解为socket，一般一个socket会占用服务器端一个端口，服务器端的端口最大数是65535)一直被占用，一旦达到了上限，则新的请求就无法被处理，接着就是大量Too Many Open Files异常，然后tomcat、nginx、apache崩溃。。

### **解决time_wait**

解决这个问题主要是从服务器参数Linux设置思考

2. 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭  
net.ipv4.tcp_tw_reuse = 1  
3. 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭  
net.ipv4.tcp_tw_recycle = 1

还可以从套接字层面来解决这个问题


Linux 内核的3.9版本带来了SO_REUSEPORT特性，该特性支持多个进程或者线程绑定到同一端口，提高服务器程序的性能，允许多个套接字 bind()以及listen() 同一个 TCP 或者 UDP 端口，并且在内核层面实现负载均衡。


### **解决close_wait**

解决该问题主要从应用代码层考虑， 因为导致被动方停在close_wait而没有进入last_ack的是由于服务器端没有正确调用函数close()。


所以如果将大量CLOSE_WAIT的解决办法总结为一句话那就是：查代码。因为问题出在服务器程序里头啊。

1. 关闭socket不及时：例如I/O线程被意外阻塞，或者I/O线程执行的用户自定义Task比例过高，导致I/O操作处理不及时，链路不能被及时释放。
2. 程序Bug，没有正常发送FIN调用close()，这可能是Netty的Bug，也可能是业务层Bug



# tcp 参数列表

在tcp设计当中我们可以对下面的参数进设计

- 开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭；
net.ipv4.tcp_syncookies = 1

- 开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；
net.ipv4.tcp_tw_reuse = 1

- 开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭；
net.ipv4.tcp_tw_recycle = 1

- 系统默认的TIMEOUT时间。
net.ipv4.tcp_fin_timeout = 5

- 当keepalive起用的时候，TCP发送keepalive消息的频度。缺省是2小时，改为20分钟(20*60s)
net.ipv4.tcp_keepalive_time = 1200

- 表示用于向外连接的端口范围。缺省情况下很小：32768到61000，改为10000到65000
net.ipv4.ip_local_port_range = 10000 65000

- SYN队列的长度，默认为1024，加大队列长度为8192，可以容纳更多等待连接的网络连接数
net.ipv4.tcp_max_syn_backlog = 8192


- 系统同时保持TIME_WAIT的最大数量，如果超过这个数字，TIME_WAIT将立刻被清除并打印警告信息。默认为180000，改为5000
net.ipv4.tcp_max_tw_buckets = 5000

1. net.ipv4.tcp_keepalive= 7200 保持长连接状况下的信息等情况

tcp_abort_on_overflow 连接队列满了怎么办在该种情况下面，


tcp_keepalive_intvl/:75
默认值为75
探测消息发送的频率，乘以tcp_keepalive_probes就得到对于从开始探测以来没有响应的连接杀除的时间。默认值为75秒，
也就是没有活动的连接将在**大约11分钟**以后将被丢弃。(对于普通应用来说,这个值有一些偏大,可以根据需要改小.特别是web类服务器需要改小该值,
**15是个比较合适的值。**

## 常用的Linux内核参数优化

```c
net.ipv4.tcp_syn_retries =1  tcp 建立连接第一阶段参数优化
net.ipv4.tcp_synack_retries=1  tcp 建立连接第三次握手
net.ipv4.tcp_syncookies = 1
net.ipv4.tcp_max_syn_backlog = 16384 半连接队列的参数



// 建立连接发送数据过程当中的数据设置
net.ipv4.tcp_keepvalie_time = 600s 
net.ipv4_tcp_keepalive_probes = 3次 发送探针的次数
net.ipv4_tcp_keepvalive_intvl = 15s 发送探针的时间间隔

//主要是断开连接后面的参数
net.ipv4.tcp_retries2 = 5
net.ipv4.tcp_fin_timeout = 2
net.ipv4.tcp_max_tw_buckets = 36000
net.ipv4.tcp_tw_recycle = 1
net.ipv4.tcp_tw_reuse = 1

开启recycle 和reuse 的前提条件是 开启tcp_timestamps  以及结合NAT工具来思考这个问题

net.ipv4.tcp_wmem = 8192 131072 16777216
net.ipv4.tcp_rmem = 32768 131072 16777216
net.ipv4.tcp_mem = 786432 1048576 1572864

```

# Linux惊群问题

在这俩面有个问题就是，我们是主服务器accept(),然后把这个连接扔给下面的worker来处理，一般来讲我们都是设置好多个worker，因此如何选择哪个worker进程来处理该次connection就是一个问题，如何由worker进程来决定谁来接管该次connection，就必然会带来无序竞争的问题，并且最终最后一个进程能够成功获该connection, 其他进程又要继续从唤醒状态进入 睡眠状态这种方式会导致大量的资源浪费的情况发生。因此解决惊群问题的关键就是如何减少这总惊群问题的发生，

1. accept 惊群问题，在Linux内核2.6当中已经解决，
2. epoll_wait() 还是存在问题，这个问题，多个进程阻塞在epoll_wait()调用上面这种基本情况，只有一个线程能够进行正常地处理epoll_wait()

我们要注意两个问题，accpet()和epoll_wait()函数的基本关系，其中，epoll_wait() 是用来通知数据是否准备好的情况，这个数据包括下面两种
1. 三次握手那种数据，比如第一syn序号问题，这个也是数据通知问题

在惊群问题里面是先调用epoll_wait() 然后再进行调用accept()函数进行处理的基本情况，情况

在Linux内核2.6之后彻底解决了accept()函数导致唤醒进程问题，只会唤醒等待队列当中的第一个进程，Linux进程等待队列是一个双向循环队列，当一个客户端连接成功时，accept()从TCP 全连接队列里面取出一个connnect, 然后服务器唤醒进程等待队列当中的第一个进程，其他进程还是继续在等待队列里面。



## nginx惊群问题

**如何生产这个问题**

主进程（master 进程）首先通过 socket() 来创建一个 sock 文件描述符用来监听，然后fork生成子进程（workers 进程），子进程将继承父进程的 sockfd（socket 文件描述符），之后子进程 accept() 后将创建已连接描述符（connected descriptor）），然后通过已连接描述符来与客户端通信

在惊群问题的累 nginx当中主要是通过圈局互斥锁来解决epoll_wait() 互斥问题的，在所有的work()进程

## Nginx对惊群现象的处理


[![ALeRgS.md.png](https://s2.ax1x.com/2019/04/13/ALeRgS.md.png)](https://imgchr.com/i/ALeRgS)


每个worker()在accept() 后面后才是

Nginx 提供了一个 accept_mutex 这个东西，这是一个加在accept上的一把互斥锁。即每个 worker 进程在执行 accept 之前都需要先获取锁，获取不到就放弃执行 accept()。有了这把锁之后，同一时刻，就只会有一个进程去 accpet()，这样就不会有惊群问题了。accept_mutex 是一个可控选项，我们可以显示地关掉，默认是打开的。


后面的Linux 提供了更多中的选择来解决惊群问题

如果不解决惊群问题，那么线程模型就是下面这种方式所示，
![VOtKzT.png](https://s2.ax1x.com/2019/06/19/VOtKzT.png)

1. EPOLLEXCLUSIVE 独占模式设置epoll,往epollfd 实例当中添加一个fd的时候，可以添加该标识符，声明为独占模式的情况，

2. SO_REUSEPORT，也可以通过该种设置方式,Linux 3.9问题，SO_REUSEPORT特性支持多个进程或者线程绑定到同一端口，提高服务器程序的性能，解决如下问题：允许多个套接字 bind()/listen() 同一个TCP/UDP端口，并且在内核层面实现负载均衡。

  - 允许多个套接字 bind()/listen() 同一个TCP/UDP端口
  - 每一个线程拥有自己的服务器套接字
  - 在服务器套接字上没有了锁的竞争，因为每个进程一个服务器套接字
  - 内核层面实现负载均衡
  - 安全层面，监听同一个端口的套接字只能位于同一个用户下面
   
采用RO_REUSEPORT方式解决Nginx问题后的线程模型问题

![VOtbYq.png](https://s2.ax1x.com/2019/06/19/VOtbYq.png)





我们如何在写代码过程当中，可以通过下面该种方式将socket设置为 SO_REUSEPORT 方式

```c
fcntl(iSvrFd,F_SETFL,flags | O_NONBLOCK |SO_REUSEPORT);
```


利用nginx代理服务器的时候，我们可以直接在配置文件当中修改

```c
//**配置相关，不详细解释**
static ngx_conf_enum_t  ngx_debug_points[] = {
       0,
       NULL },
 
+    { ngx_string("so_reuseport"),
+      NGX_MAIN_CONF|NGX_DIRECT_CONF|NGX_CONF_TAKE1,
+      ngx_set_so_reuseport,
+      0,
+      0,
+      NULL },
+
     { ngx_string("debug_points"),
       NGX_MAIN_CONF|NGX_DIRECT_CONF|NGX_CONF_TAKE1,
       ngx_conf_set_enum_slot,
 
     return NGX_CONF_OK;
 }

```

# 项目难点以及学习到的东西

学习到了什么Linux 系统以及网络性能优化

1. 系统优化，内存，磁盘，I/O操作
2. 内核TCP/IP协议stack的参数优化
3. 问题排查，debug,内存泄漏

主要来及与Linux性能

- 36 如何评估网络性能
- 43 网络性能优化
- 40 网络的请求延迟变大
- 48 服务器丢包的问题



# 参考资料

- [Too many open files (CLOSE_WAIT connections) · Issue #4575 · kennethreitz/requests](https://github.com/kennethreitz/requests/issues/4575)

- [关于TCP 半连接队列和全连接队列  |阿里中间件团队博客](http://jm.taobao.org/2017/05/25/525-1/)

- [记一次惊心的网站TCP队列问题排查经历](https://zhuanlan.zhihu.com/p/36731397)

- [Wireshark抓取TCP报文类型为RST的方法 - u010192132的专栏 - CSDN博客](https://blog.csdn.net/u010192132/article/details/44095733)

- [大并发下listen的连接完成对列backlog太小导致客户超时，服务器效率低下 ](https://blog.csdn.net/lizhi200404520/article/details/6981272)

- [How TCP backlog works in Linux](http://veithen.io/2014/01/01/how-tcp-backlog-works-in-linux.html)

- [Linux使用ss命令查看socket状态](https://blog.51cto.com/215687833/1836119)

- [Nginx工作原理（Master+Worker)](https://blog.csdn.net/Kim_Weir/article/details/80036462)

