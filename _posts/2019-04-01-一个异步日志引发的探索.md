---
layout: post
title:  "一个异步日志引发的探索"
date:   2019-02-15 22:14:54
categories: jekyll
tags: 
    - 并发
    - 锁
    - 多线程
comments: true
---
* content
{:toc}


# 异步日志设计
在项目当中，前端应用线程产生了大量的日志系统，我们知道在现代计算机发展当中，CPU的处理速度和访问主存以及磁盘I/0一直是个瓶颈。
- 从计算机体系架构专家的角度来讲，就是要怎么提高CPU更高更大的多层次缓存， 比如现代CPU的L1缓存，L2缓存，L3缓存。
- 从我们程序员的角度来讲，在日常的编码当中，要考虑的估计就是在编码过程的当中做到下面几点来提升程序的性能
    - 在应用当中应该尽量减少直接磁盘1/0，I/O等待
    - 如何充分利用设计合理的进程和线程模型，减少不必要进程和线程切换，充分利用的TLB缓存，

目前的日志模型主要下面三种

1. Asynchronous Logger 异步模式
2. Mixing Synchronous and Asynchronous Loggers 同步和异步混合模式
3.  Synchronous Logger 同步模式

趁着最近在复习一些计算机系统结构方面的知识以及总结之前做的项目，谈一谈如何从优化程序设计。

今天这一篇，先从我之前项目基于双缓冲区的异步日志这个点说起。

## 同步日志
同步日志，即当输出日志时，必须等待日志输出语句执行完毕后，前端线程才能执行后面的业务逻辑语句。


**同步日志存在的问题**

1. 每条日志内存都会调用write,write为系统调用，系统调用是会尝试开销的
2. 当在应用程序的关键代码出调用write会不会影响原有业务逻辑处的代码不能正常执行，或者要停顿很多

## 异步日志
为了避免在应用程序前端代码直接磁盘I/0带来的性能影响，我们将写日志这个不影响应用程序性能的杂活分离出来，前端只要将日志放到中间站，就可以立即返回继续处理前面的业务，剩下交由第三方专门线程来处理，这就是异步日志。这个模型实质就就可以看做是生产者和消费者的基本模式。

![A2nUbj.png](https://s2.ax1x.com/2019/04/04/A2nUbj.png)


## 吞吐量

**同步锁带来效率降低**

我在项目当中采用的异步日志主要是采用双缓冲区A和B，前端线程将日志生产到A缓冲区，后端专用日志线程将B写入磁盘，当A满了之后就交换A和B两个。既然是一个生成者和消费者模式，那么缓冲区本身是一种互斥资源，在具体编码过程中要考虑对临界区互斥资源的保护，所以在项目当中我简单的使用一个互斥锁机制，多个前端业务线程在写日志的时候都要获取这把锁，

# Java常用日志系统
log4j，logback是java开发当中常用的日志框架，深入了解了下该日志库的实现，我发现还是依靠JUC包下面的阻塞队列来是实现日志系统这个典型的多生产者和单一消费者模式，

我们知道在java当中实现消费者和生产者无非就是下面这几种
1. 使用synchronized同步关键字
2. 使用Lock下面的ReetrantLock 和condtion条件变量
3. 直接使用基于AQS同步队列器的阻塞队列，不需要我们在进行对临界资源进行加锁和解锁

log4j、logback 等日志系统有对应的AsyncAppender实现异步队列，都选择了有界的ArrayBlockingQueue。为何不选择无界的基于链表的LinkedBlockingQueue？主要是基于内存考虑的，当生产者速度过快的时候，无界队列要为所有的日志分配内存，导致内存溢出。

顺便去了解了下log4j的组件

1. Logger
2. Appender，表示如何处理日志，可以写本地文件，可以写远程文件，也可以输出到消息队列，等等。最常见的场景就是写本地文件,也就是写入到本地的磁盘当中。


# 无锁异步日志

Log4j采用的阻塞队列，依靠conditon条件变量进行await()和睡眠线程signal()，在多线程编程当中大量的线程睡眠和唤醒，需要操作系统的底层支持，
也就是上下文切换，导致服务器性能下降。因此有人就考虑能不能实现无锁，这样就解决了线程对锁的竞争带来的效率下降问题。



>发现写日志qps在2000 以上时，系统的上下文切换也会相应增高3000-4000次，说明涉及到大量的线程并发切换。

我这里面引用下技术博客的一篇博文当中的数据，我们知道并发多线程竞争下解决冲突主要有下面三种方案
1. 锁
2. CAS原子操作
3. 实现无锁操作

针对上述三种方案的性能对别，下面即将提到的Disrupotr论文就做过这么一个实验室
- 这个测试程序定义一个函数， 该函数的实现对一个64位的整数计数器循环自增5亿次
- 电脑配置 2. 4G 6核
- 分别设置一下几组对比实验
    - 单线程不涉及线程安全控制
    - 单线程加锁,采用的retrantlock 
    - 单线程加CAS
    - 单线程加volatile修饰变量
    - 两个线程协同操作加锁
    - 两个线程协同利用cas实现并发
  
>the focus of this experiment is to call a function which increments a 64-bit counter in a loop 500 million times. This can be executed by a single thread on a 2.4Ghz Intel Westmere EP in just 300ms if written in Java
  

[Disruptor论文地址](https://lmax-exchange.github.io/disruptor/files/Disruptor-1.0.pdf)

个人觉得这篇论文还是可以好好看下的，谈到并发线程的知识，比如从计算机系统结构的cache line 和内存屏障等方面讨论，对理解各种编程语言的内存模型是很不错，并且不仅仅局限于java语言。

**实验对比结果**
![A2nPER.png](https://s2.ax1x.com/2019/04/04/A2nPER.png)


在单线程环境下面完成的时间为300ms,CAS操作是5700ms, 加锁Lock操作为10000，实验室结果表示


- 在单线程情况下 **无锁操作>volatile>CAS>Lock** 
- 在多线程环境下 由于必须使用锁或者CAS操作  **CAS的性能远远优于Lock前者大约是后者的8倍。** 其实这也可以很好地解释了之前看的JUC包里面的ConcurrentHash 为何JDK1.8要将JDK1.7的分段锁ReetrantLock 进一步优化为CAS操作 + synchronized+ volatile。

JDK1.7




## RingBUffer + Disruptor
Disruptor是英国外汇交易公司LMAX开发的一个高性能队列，研发的初衷是解决内存队列的延迟问题（在性能测试中发现竟然与I/O操作处于同样的数量级）。基于Disruptor开发的系统单线程能支撑每秒600万订单，2010年在QCon演讲后，获得了业界关注。2011年，企业应用软件专家Martin Fowler专门撰写长文介绍。同年它还获得了Oracle官方的Duke大奖。

目前， 包括Apache Storm, Camel, Log4j 2等项目都应用到了Disruptor。


### 什么是ringbuffer ？
中文名叫做环形缓冲区，是一个内存环，底层是一个数组，所以我们可以预先分配内存，这样可以避免频繁地创建和销毁内存带来的开销；试想如果采用链表，每增加一条数据记录都要创建一个对象，当数据要清空时，要销毁，而且基于数组的形式我们可以随机访问，比如ringbuffer当中我们可以对数组大小取模运算，访问下标元素


![A2eYJf.png](https://s2.ax1x.com/2019/04/04/A2eYJf.png)

该环形缓冲区有一下几个设计特点

1. 一般我们环形槽位设置为2的N次方法，然后index = key& (length-1),这种思想跟Java hashMap求hashtable下标是一样的思想，都是采用这种快速
2. 

### Disruptor与Ringbuffer的关系

Ringbuffer 定义了如何存储数据的结构，Dispruptor则定义了如何控制多线程环境系对RingBuffer数结构的数据访问。

## google leveldb日志系统
leveldb的总体设计架构:

[![VWCB6g.md.png](https://s2.ax1x.com/2019/06/12/VWCB6g.md.png)](https://imgchr.com/i/VWCB6g)



leveldb同样采用 WAL技术，写入数据库之前先写入日志文件，当应用要插入一条记录时，leveldb首先是将其写入到log中，若成功，则继续将其插入到内存中memtable中。因此，当系统故障而memtable又没有来得及将数据存放到磁盘中，那么就可以通过log文件来恢复数据，保证数据不会丢失。当一个memtable大小达到一定程度的时候，就会变成在immemtable 不可变的， 然后在适当的时候imm memtable就会合并到磁盘当中的sstable里面。 

leveldb暴露给用户使用的接口主要有下面几个

- Write(k,v)，对外的接口
- get(k) 或者某个key对应的value情况
- Op log，操作日志记录文件
- memtable，数据库存储的内存结构
- Immutable memtable，待落盘的数据库内存数据
- sstable，落盘后的磁盘存储结构
- manifest，LevelDB 元信息清单，包括数据库的配置信息和中间使用的文件列表
- current，当前正在使用的文件清单

```c
class Writer {
 public:
  explicit Writer(WritableFile* dest);
  ~Writer();
  Status AddRecord(const Slice& slice);
 private:
  WritableFile* dest_;  //以一个WritableFile对象作为Writer的成员，Writer则是将要插入的记录插入到dest_中
  int block_offset_;       // 当前位置在Block中的偏移
  uint32_t type_crc_[kMaxRecordType + 1];//CRC
  Status EmitPhysicalRecord(RecordType type, const char* ptr, size_t length);//调用Append写入数据
};
```
Writer类当中暴露给日志操作的就是AddRecord函数

一个日志文件的格式如下所示的操作

![VWmmKP.png](https://s2.ax1x.com/2019/06/12/VWmmKP.png)

可以看到一个完整的log由多个block 组成, block 的大小是固定的:


### 一次write过程

数据库现在也都是采用批量写入的方式来操作，提高效率

```c
Status DBImpl::Write(const WriteOptions& options, WriteBatch* my_batch) {
  Writer w(&mutex_);
  w.batch = my_batch;
  w.sync = options.sync;//default is false
  w.done = false;
  MutexLock l(&mutex_);
  writers_.push_back(&w);//将writer加入任务队列deque
  while (!w.done && &w != writers_.front()) {//未执行，且不在任务队列首部，则等待
    w.cv.Wait();
  }
  if (w.done) {//已执行完毕，返回status
    return w.status;
  }
  //确保有Memtable和log文件可以用于数据的写入，对已写满的Memtable后台调度Compaction
  Status status = MakeRoomForWrite(my_batch == NULL);
  if (status.ok() && my_batch != NULL) {// 当batch为空时，是准备执行compactions操作，否则插入记录
    WriteBatch* updates = BuildBatchGroup(&last_writer);//将任务队列中所有的非同步任务组织在一起形成一个WriteBatch，一起批量写入，可以极大的提升写的效率
    WriteBatchInternal::SetSequence(updates, last_sequence + 1);
    last_sequence += WriteBatchInternal::Count(updates);
    {
      mutex_.Unlock();
      //调用fwrite将记录写入log文件中
      status = log_->AddRecord(WriteBatchInternal::Contents(updates));
      bool sync_error = false;
      if (status.ok() && options.sync) {
        status = logfile_->Sync();//若设置了同步，则每次写成功后都同步一次同步到磁盘当中去
      }
      //操作
      if (status.ok()) {
      //批量写入memtable的
        status = WriteBatchInternal::InsertInto(updates, mem_);//将updates中的记录插入到mem_中
      }
      mutex_.Lock();
    }
    if (updates == tmp_batch_) tmp_batch_->Clear();
    //版本更新操作
    versions_->SetLastSequence(last_sequence);
  }
  while (true) {//等待队列中的其它任务
    Writer* ready = writers_.front();
    writers_.pop_front();
    if (ready != &w) {
      ready->status = status;
      ready->done = true;
      ready->cv.Signal();
    }
    if (ready == last_writer) break;
  }
}
```

写操作可能会导致Memtable写满，此时就需要将其转化为immutable memtable，并在后台调用合并操作将其转化为SSTable。这是在MakeRoomForWrite()中完成的。

### 一次get() 操作

```c
Status DBImpl::Get(const ReadOptions& options,
                   const Slice& key,
                   std::string* value) {
  Status s;
  MutexLock l(&mutex_);
  MemTable* mem = mem_;
  MemTable* imm = imm_;
  Version* current = versions_->current();
  mem->Ref();
  if (imm != NULL) imm->Ref();
  current->Ref();

  bool have_stat_update = false;
  Version::GetStats stats;

  // Unlock while reading from files and memtables
  {
  //主要的查找操作，，
    mutex_.Unlock();
    // First look in the memtable, then in the immutable memtable (if any).
    LookupKey lkey(key, snapshot);
    if (mem->Get(lkey, value, &s)) {//首先在memtable中查找
      // Done
    } else if (imm != NULL && imm->Get(lkey, value, &s)) {//若没找到则继续在immutable memtable中查找
      // Done
    } else {
   
   //若还没找到，则继续在sstable中查找
      s = current->Get(options, lkey, value, &stats);
      have_stat_update = true;
    }
    mutex_.Lock();
  }

  if (have_stat_update && current->UpdateStats(stats)) {
    MaybeScheduleCompaction();//可能进行campact操作
  }
  mem->Unref();
  if (imm != NULL) imm->Unref();
  current->Unref();
  //最后返回调获取结果
  return s;
}
```
leveldb是按memtable, immutable memtable, SSTable的优先级来进行查找的。

无论是在write(),还是get(),都是通过锁来实现互斥操作，只允许单线程对数据进行写操作，不支持多线程并发操作的，这也是leveldb数据库的缺陷之一，facebook对该数据库进行一个improve,得到一个rockdb，支持多线程操作；但是支持多个Reader，以及内部一个用于Compact的Background线程的并发模型. 因此用户开多个线程进行Write意义不大，因为内部会做串行化处理单线程 而如果能合理用上多个磁盘的话，多线程Read可以提高吞吐.

>多线程读，单线程写，读写不互斥

上述过程可以总结为如下

![VWe7HU.png](https://s2.ax1x.com/2019/06/12/VWe7HU.png)

